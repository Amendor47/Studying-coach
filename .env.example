# LLM Provider Configuration
LLM_PROVIDER=ollama
OLLAMA_HOST=http://127.0.0.1:11434
OLLAMA_MODEL=llama3.1:8b

# Alternative providers (uncomment to use)
# LLM_PROVIDER=gpt4all
# GPT4ALL_MODEL=mistral-7b-instruct-v0.1.Q4_0.gguf

# LLM_PROVIDER=llama_cpp
# LLAMA_CPP_MODEL_PATH=/path/to/model.gguf

# Embeddings Configuration
EMBEDDINGS_MODEL=sentence-transformers/all-MiniLM-L6-v2

# CORS Configuration (for development)
CORS_ORIGINS=http://localhost:5000,http://127.0.0.1:5000

# Optional: OpenAI API key for fallback
# OPENAI_API_KEY=your-api-key-here

# Cache and Performance Settings
LLM_CACHE_TTL=3600
LLM_MAX_TOKENS=2048
LLM_TEMPERATURE=0.2